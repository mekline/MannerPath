alldata[alldata$SpatialCue == 0,]$SpatialCue <- "Spatial.Absent"
######
# Final item inclusion/checking
# Find out: How many items did each person complete?
#Make sure the dropped people really got dropped, they snuck back in during item comparisons...
subtable <- subtable[c("Participant","To.include")]
names(subtable) <- c("Subject","ToInclude")
alldata <- merge(alldata, subtable, by=c("Subject"))
alldata <- alldata[alldata$ToInclude == 1,]
numSigns <- aggregate(alldata$WordOrder, by=list(alldata$Subject),length)
#Yay! Everyone did all the trials!
#################################################################
## REPORT DESCRIPTIVES
#Report S counts
length(unique(alldata$Subject))
#Report counts of SOV versus SVO instances in Free and Hand conditions
table(alldata$WordOrder.Classified, alldata$Object.Type, alldata$GestureCondition)
#And when were spatial cues actually produced?
table(alldata$SpatialCue, alldata$WordOrder.Classified, alldata$Object.Type)
#Let's look just at the second experiment to see if they really did it...
instructiondata <- alldata[alldata$GestureCondition == "Case",]
table(instructiondata$SpatialCue, instructiondata$WordOrder.Classified, instructiondata$Object.Type)
#What about early casemarkers?
noinstructiondata <- alldata[alldata$GestureCondition == "Free",]
table(noinstructiondata$SpatialCue, noinstructiondata$WordOrder.Classified, noinstructiondata$Object.Type)
#######
# Some more descriptives for the paper
#How many items are just an S, O, and V?
#Does Long not equal Clean?
#Does type equal Unclassified? 191
#Parentheses?
nrow(alldata[alldata$WordOrder == "(SO)V",]) #<- actually all got coded this way!
#Eh, let's go ahead and mark those in case anyone is worried about our data coding....
alldata$SuperGoodResponse <- "Yes"
alldata[alldata$Final.Full.WordOrder != alldata$WordOrder,]$SuperGoodResponse <- "No"
alldata[alldata$WordOrder.Classified == "Unclassified",]$SuperGoodResponse <- "No"
alldata[alldata$WordOrder == "(SO)V",]$SuperGoodResponse <- "No"
#Little pause for some calculations about our classification scheme...
foo <- alldata[alldata$Final.Full.WordOrder != alldata$WordOrder & alldata$WordOrder.Classified != "Unclassified",]$Final.Full.WordOrder
goo <- as.data.frame(foo)
goo$len <- unlist(lapply(foo, nchar))
goo <- goo[goo$len > 3,]
goo[order(goo$foo),]
#(And do some manual checking about items that might have been misclassified)
#OK: For items longer than length 3 that DID get classified, here are places we might have mistakes:
# OVOSV - maybe not SOV
# SOVSVO 2 - maybe not SVO
####
# Now do it by scores-per-participant. (Need this to make the bootstrapped confidence intervals...)
#Drop Unclassified items!!
alldata <- alldata[!(alldata$WordOrder.Classified == "Unclassified"),]
alldata <- alldata[!(alldata$SpatialCue == "?"),]
#Optionally, drop non SuperGoodResponses!
#alldata <- alldata[alldata$SuperGoodResponse == "Yes",]
#Make scores for each participant
alldata$ChoseLateral <- 0
alldata[alldata$WordOrder.Classified == "VerbLateral",]$ChoseLateral <- 1
ParticipantScores <- aggregate(alldata$ChoseLateral, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(ParticipantScores) <- c("Subject", "Object.Type", "GestureCondition", "ChoseLateral")
#Table for scores too
with(ParticipantScores, tapply(ChoseLateral, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#Time for bootstrapped confidence intervals around the means of the 4 conditions!
PersonFree.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Person" & ParticipantScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Person" & ParticipantScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Object" & ParticipantScores$GestureCondition=="Free",]$ChoseLateral, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(ParticipantScores[ParticipantScores$Object.Type=="Object" & ParticipantScores$GestureCondition=="Case",]$ChoseLateral, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
#And scores on Spatial stuff!
alldata$Casemarked <- 0
alldata[alldata$SpatialCue == "Spatial.Present",]$Casemarked <- 1
SpatialScores <- aggregate(alldata$Casemarked, by=list(alldata$Subject, alldata$WordOrder.Classified, alldata$GestureCondition), mean.na.rm)
names(SpatialScores) <- c("Subject", "WordOrder.Classified", "GestureCondition", "Casemarked")
#Table for scores too
with(SpatialScores, tapply(Casemarked, list(WordOrder.Classified, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#Time for bootstrapped confidence intervals around the means of the 4 conditions!
PersonFree.boot.mean = bootstrap(SpatialScores[SpatialScores$WordOrder.Classified=="VerbLateral" & SpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(SpatialScores[SpatialScores$WordOrder.Classified=="VerbLateral" & SpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(SpatialScores[SpatialScores$WordOrder.Classified=="VerbMedial" & SpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(SpatialScores[SpatialScores$WordOrder.Classified=="VerbMedial" & SpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
#And did they casemark differently depending on animacy?
AnimacySpatialScores <- aggregate(alldata$Casemarked, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(AnimacySpatialScores) <- c("Subject", "Object.Type", "GestureCondition", "Casemarked")
with(AnimacySpatialScores, tapply(Casemarked, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#Time for bootstrapped confidence intervals around the means of the 4 conditions!
PersonFree.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Person" & AnimacySpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(PersonFree.boot.mean$thetastar, c(0.025, 0.975))
PersonHand.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Person" & AnimacySpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(PersonHand.boot.mean$thetastar, c(0.025, 0.975))
ObjectFree.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Object" & AnimacySpatialScores$GestureCondition=="Free",]$Casemarked, 1000, mean)
quantile(ObjectFree.boot.mean$thetastar, c(0.025, 0.975))
ObjectHand.boot.mean = bootstrap(AnimacySpatialScores[AnimacySpatialScores$Object.Type=="Object" & AnimacySpatialScores$GestureCondition=="Case",]$Casemarked, 1000, mean)
quantile(ObjectHand.boot.mean$thetastar, c(0.025, 0.975))
#########################################
##STATISTICAL TESTS!!
#########################################
alldata$WordOrder.Classified <- as.factor(alldata$WordOrder.Classified)
alldata$Object.Type <- as.factor(alldata$Object.Type)
alldata$SpatialCue <- as.factor(alldata$SpatialCue)
alldata$GestureCondition <- as.factor(alldata$GestureCondition)
freedata <- alldata[alldata$GestureCondition == "Free",]
handdata <- alldata[alldata$GestureCondition == "Case",]
freedata$WordOrder.Classified <- as.factor(freedata$WordOrder.Classified)
handdata$WordOrder.Classified <- as.factor(handdata$WordOrder.Classified)
freedata$Object.Type <- as.factor(freedata$Object.Type)
handdata$Object.Type <- as.factor(handdata$Object.Type)
#Within Experiments- were people more likely to use SVO with Animate?
free_model <- lmer(WordOrder.Classified ~ Object.Type  + (1+Object.Type|Subject), data=freedata, family="binomial")
summary(free_model)
hand_model <- lmer(WordOrder.Classified ~ Object.Type  + (1+Object.Type|Subject), data=handdata, family="binomial")
summary(hand_model)
#Between Experiments! - was there an interaction between Experiment and the above?
word_order_model <- lmer(WordOrder.Classified ~ Object.Type*GestureCondition  + (1+Object.Type|Subject), data=alldata, family="binomial")
summary(word_order_model)
#Between cues  - was there an interaction between ACTUALLY USING SPACE and useing SVO for animates?
spatial_model <- lmer(SpatialCue ~ WordOrder.Classified  + (1+Object.Type|Subject), data=alldata, family="binomial")
summary(spatial_model)
word_order_spatial_model <- lmer(WordOrder.Classified ~ Object.Type*SpatialCue  + (1+Object.Type|Subject), data=alldata, family="binomial")
summary(word_order_spatial_model)
#Did being animate make you more likely to casemark? No.  It looks like people took it as a general strategy.
cue_model <- lmer(SpatialCue ~ Object.Type*GestureCondition  + (1+Object.Type|Subject), data=alldata, family="binomial")
summary(cue_model)
######
# A new thing. Need more detail about the casemarking in the casemarked trials! To facilitate, print out
# a new file, SpatialCasemarking_Casemarked_Trials.csv, with just the (legal subject) casemarking
# trials.
orig_all_data <- read.csv(paste0(directory, "/SpatialCasemarking_AllGestureData.csv"), header = TRUE)
alldata_short <- alldata[,c("Subject", "Trial.Number","GestureCondition","SpatialCue", "Final.Full.WordOrder")]
foo <- merge(orig_all_data, alldata_short, by=c("Subject", "Trial.Number","GestureCondition"))
foo$SpatialCue.FinalDecision <- foo$SpatialCue
foo <- foo[foo$SpatialCue.FinalDecision == "Spatial.Present",]
write.csv(foo, file = paste0(directory, "/SpatialCasemarking_OnlyCaseTrials.csv"))
#####
# Another new thing.  We want to check if Embodiment (in the second task)
# made a difference for SOV use (ie maybe we accidentally did an embodiment
# manipulation...).  For this, read in the new Embodiment coding that Miguel
# did ~ 10/22/14
embodiment_data <- read.csv(paste0(directory, "/EmbodimentRecode.csv"), header = TRUE)
#drop some duplicate columns we dont' need...
embodiment_data <- embodiment_data[,c("Clipped.Movie.File","Trial.Number", "Agent.Embod","Verb.Embod","Patient.Embod")]
alldata <- merge(alldata, embodiment_data, by=c("Clipped.Movie.File","Trial.Number"),all.X=TRUE, all.y=FALSE)
#Did Embodiment change across the 2 conditions? Check Agent and Verb
table(alldata$Agent.Embod, alldata$Object.Type, alldata$GestureCondition)
table(alldata$Verb.Embod, alldata$Object.Type, alldata$GestureCondition)
table(alldata$Patient.Embod, alldata$Object.Type, alldata$GestureCondition)
#Fascinating! Agent and Patient embodiment is actually about the same,
# but verb is very different:
#For verb, Embodiment is 0 on many more trials in Case.  But happily, there it's
#about half and half, so we should be able to measure effects! Let's quantify that...
#OK, I thought about it: Embodicment hyp is centrally about avoiding role
#conflict between V and O.  This means a) gotta recode WordOrder, and b)
# the metric we care about is intersect(V,O)
#Pilot: drop ?s!
alldata <- alldata[alldata$Agent.Embod != "?",]
alldata <- alldata[alldata$Verb.Embod != "?",]
alldata <- alldata[alldata$Patient.Embod != "?",]
alldata$Agent.Embod <- as.numeric(as.character(alldata$Agent.Embod))
alldata$Verb.Embod <- as.numeric(as.character(alldata$Verb.Embod))
alldata$Patient.Embod <- as.numeric(as.character(alldata$Patient.Embod))
alldata$PV.Embod <- (alldata$Verb.Embod == 1) & (alldata$Patient.Embod == 1)
EmbodAgentScores <- aggregate(alldata$Agent.Embod, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(EmbodAgentScores) <- c("Subject", "Object.Type", "GestureCondition", "Agent.Embod")
EmbodVerbScores <- aggregate(alldata$Verb.Embod, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(EmbodVerbScores) <- c("Subject", "Object.Type", "GestureCondition", "Verb.Embod")
EmbodPatientScores <- aggregate(alldata$Patient.Embod, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(EmbodPatientScores) <- c("Subject", "Object.Type", "GestureCondition", "Patient.Embod")
EmbodPVScores <- aggregate(alldata$PV.Embod, by=list(alldata$Subject, alldata$Object.Type, alldata$GestureCondition), mean.na.rm)
names(EmbodPVScores) <- c("Subject", "Object.Type", "GestureCondition", "PV.Embod")
#Table for scores too
with(EmbodAgentScores, tapply(Agent.Embod, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
with(EmbodVerbScores, tapply(Verb.Embod, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
with(EmbodPatientScores, tapply(Patient.Embod, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
with(EmbodPVScores, tapply(PV.Embod, list(Object.Type, GestureCondition), mean, na.rm=TRUE), drop=TRUE)
#OK! So it looks like our manipulation did decrease PV from Free (65%) to Case (30%)
alldata$WordOrder.Embod.Classified <- "Unclassified"
alldata[alldata$WordOrder == "SOV",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "OSV",]$WordOrder.Embod.Classified <- "Adjacent"
alldata[alldata$WordOrder == "VSO",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "VOS",]$WordOrder.Embod.Classified <- "NonAdjacent"
#Parenthesis cases
alldata[alldata$WordOrder == "V(OS)",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "V(SO)",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "(SO)V",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "(OS)V",]$WordOrder.Embod.Classified <- "NonAdjacent"
alldata[alldata$WordOrder == "SVO",]$WordOrder.Embod.Classified <- "Adjacent"
alldata[alldata$WordOrder == "OVS",]$WordOrder.Embod.Classified <- "NonAdjacent"
#OK, now let's look within the Casemarking task.  Did the people who
#Embodied their (verb/patient) gestures use more SVO for AnimatePatients?
casedata <- alldata[alldata$GestureCondition =='Case',]
freedata <- alldata[alldata$GestureCondition =='Free',]
table(casedata$WordOrder.Embod.Classified, casedata$Object.Type, casedata$PV.Embod)
table(freedata$WordOrder.Embod.Classified, freedata$Object.Type, freedata$PV.Embod)
#OK, so looks like in case, most of the Person ones are still Lateral even if
#conflict is present.  Let's check if they are the weird Matt hall ones!
casedata[casedata$PV.Embod == FALSE,c('WordOrder.Classified', 'Final.Full.WordOrder')]
#Did casemarking just produce non-embodiment?  Let's look at how closely associated the 2 are
peopledata <- alldata[alldata$Object.Type == 'Person',]
table(peopledata$PV.Embod, peopledata$SpatialCue)
table(casedata$WordOrder.Embod.Classified, casedata$Object.Type, casedata$PV.Embod)
table(freedata$WordOrder.Embod.Classified, freedata$Object.Type, freedata$PV.Embod)
setwd("~/Dropbox/_Projects/MannerPathCategories/Analysis/Analysis 12-12-14")
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
library(stringr)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"turkdemo") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes (using dplyr methods)
df.complete = subset(df.complete,status %in% c(3,4))
#filter to a particular day (if I haven't set codeversions). OR together multiple days if needed
df.complete$currentVersion = str_detect(df.complete$beginhit, "2014-12-11")
df.complete = subset(df.complete, currentVersion %in% TRUE)
# Structure data ----------------------------------------------------------
#Note: Compile in wide form: 1 row/participant; each trial gets a series of column names, formatted XYFIELD_#
#Also, no extra underscores in the column names, this breaks wideToLong
#df.wide = data.frame(NULL)
df.wide = data.frame(matrix(nrow=nrow(df.complete),ncol=4))
colnames(df.wide) = c("participant","workerId","browser","beginhit") #will dynamically add columns from datastring below
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete$datastring[i])
#Note! Some badness is happening in finding these indices, need to fix this loop so it doesn't go beyond a's limit
mylength = length(a$data)
print(mylength)
#Weird: Some of the people (~10) have the wrong number of blocks!  For now, just take the ones who are length 23, but what the hell!
if (mylength == 23){
df.wide$participant[i] = i
df.wide$workerId[i] = a$workerId
df.wide$browser[i] = df.complete$browser[i]
df.wide$beginhit[i] = df.complete$beginhit[i]
#cycle through all the trials, but only record where isTestTrial = 1
for (j in 1:mylength){
if(a$data[[j]]$trialdata$isTestTrial == "1"){
df.wide[[paste("rt_",j, sep="")]][i] = a$data[[j]]$trialdata$rt
df.wide[[paste("keypress_",j, sep="")]][i] = a$data[[j]]$trialdata$key_press
df.wide[[paste("stimcondition_",j, sep="")]][i] = a$data[[j]]$trialdata$stimcondition
df.wide[[paste("exposureManner_",j, sep="")]][i] = a$data[[j]]$trialdata$exposure_manner
df.wide[[paste("exposurePath_",j, sep="")]][i] = a$data[[j]]$trialdata$exposure_path
df.wide[[paste("exposureNumber_",j, sep="")]][i] = a$data[[j]]$trialdata$exposure_number
df.wide[[paste("condition_",j, sep="")]][i] = a$data[[j]]$trialdata$condition_name
} #Else just don't make any columns right now!!!
}
#And grab the info we need from the last 'trial' (feedback)
if (is.null(a$data[[mylength-1]]$trialdata$Q0)){df.wide$feedback[i] = "none"
}else{
df.wide$feedback[i] = a$data[[mylength-1]]$trialdata$Q0
}
}
} #End of this participant
#Weird behavior!  If a cell is not assigned, R is filling it in with the values from the first row.  What?!  Anyway I made it stop but not sure how.  Explore this more.
#I got those wrong-lenght participants to be assigned a participant no of NA, which is something, anyway.
#Reformat into long form!
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
nrow(df.wide)
df.wide[!is.na(df.wide$participant),]
nrow(df.wide)
df.wide = df.wide[!is.na(df.wide$participant),]
nrow(df.wide)
#Reformat into long form!
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
names(df.long)
#create factors
df.long = mutate(df.long, participant = as.numeric(participant),
trial = as.numeric(as.character(trial)),
rt = as.numeric(as.character(rt)),
keypress = as.numeric(as.character(keypress))-48, #transform keycodes to numerals!
stimcondition = factor(stimcondition,levels=c("mismatch","match", "mannerchange","pathchange")),
exposureNumber = as.numeric(as.character(exposureNumber)),
condition = factor(condition, levels=c("Noun","Verb")))
names(df.long)
df.long = df.long[order(df.long$participant,df.long$trial),]
df.long
names(df.long)
df.long[,c("participant","trial","keypress","stimcondition","condition")]
mean.na.rm <- function(x) { mean(x,na.rm=T) }
sum.na.rm <- function(x) { sum(x,na.rm=T) }
stderr <- function(x) sqrt(var(x)/length(x))
mannerScores = aggregate(df.long$keypress, by=list(df.long$participant), mean.na.rm)
mannerScores
names(df.long)
mannerScores = aggregate(df.long[df.long$stimcondition=="mannerchange",]$keypress, by=list(df.long[df.long$stimcondition=="mannerchange",]$participant), mean.na.rm)
mannerScores
mannerScores = aggregate(df.long[df.long$stimcondition=="match",]$keypress, by=list(df.long[df.long$stimcondition=="match",]$participant), mean.na.rm)
mannerScores
mannerScores = aggregate(df.long[df.long$stimcondition=="mannerchange",]$keypress, by=list(df.long[df.long$stimcondition=="mannerchange",]$participant), mean.na.rm)
pathScores = aggregate(df.long[df.long$stimcondition=="pathchange",]$keypress, by=list(df.long[df.long$stimcondition=="pathchange",]$participant), mean.na.rm)
names(pathScores) = c("participant", "pathscore")
names(mannerScores) = c("participant", "mannerscore")
merge(mannerScores, pathScores, by="participant")
Scores = merge(mannerScores, pathScores, by="participant")
abs(01)
abs(-01)
mannerScores = aggregate(df.long[df.long$stimcondition=="mannerchange",]$keypress, by=list(df.long[df.long$stimcondition=="mannerchange",]$participant, df.long[df.long$stimcondition=="mannerchange",]$condition), mean.na.rm)
names(mannerScores) = c("participant", "condition", "mannerscore")
pathScores = aggregate(df.long[df.long$stimcondition=="pathchange",]$keypress, by=list(df.long[df.long$stimcondition=="pathchange",]$participant df.long[df.long$stimcondition=="pathchange",]$condition), mean.na.rm)
names(pathScores) = c("participant", "condition", "pathscore")
Scores = merge(mannerScores, pathScores, by=c("participant", "condition"))
mannerScores = aggregate(df.long[df.long$stimcondition=="mannerchange",]$keypress, by=list(df.long[df.long$stimcondition=="mannerchange",]$participant, df.long[df.long$stimcondition=="mannerchange",]$condition), mean.na.rm)
names(mannerScores) = c("participant", "condition", "mannerscore")
pathScores = aggregate(df.long[df.long$stimcondition=="pathchange",]$keypress, by=list(df.long[df.long$stimcondition=="pathchange",]$participant, df.long[df.long$stimcondition=="pathchange",]$condition), mean.na.rm)
names(pathScores) = c("participant", "condition", "pathscore")
Scores = merge(mannerScores, pathScores, by=c("participant", "condition"))
Scores
Scores$diffscore = abs(Scores$mannerscore - Scores$pathscore)
Scores
with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
t.test(Scores[Scores$condition == "Noun"]$diffscore, Scores[Scores$condition == "Verb"]$diffscore))
t.test(Scores[Scores$condition == "Noun"]$diffscore, Scores[Scores$condition == "Verb"]$diffscore)
t.test(Scores[Scores$condition == "Noun",]$diffscore, Scores[Scores$condition == "Verb",]$diffscore)
Scores$ILikeMannerscore = Scores$pathscore - Scores$mannercore
Scores$ILikeMannerscore = Scores$pathscore - Scores$mannerscore
Scores$ILikeMannerscore = Scores$pathscore - Scores$mannerscore
with(Scores, tapply(ILikeMannerscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
Scores$ILikeMannerscore
nrow(Scores[Scores$condition=="Verb",])
nrow(Scores[Scores$condition=="Noun",])
with(Scores, tapply(ILikeMannerscore, list(condition), stderr, na.rm=TRUE), drop=TRUE)
nj
quit
asdf
1+2
with(Scores, tapply(ILikeMannerscore, list(condition), stderr), drop=TRUE)
with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
se(c(1,2,3))
ggplot(Scores, aes(x=condition, y=diffscore, fill=supp)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=diffscore-stderr, ymax=diffscores+stderr),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
library(ggplot)
library(ggplot2)
install.packages(c("digest", "httr", "languageR", "maps", "mboost", "multcomp", "RColorBrewer", "reshape2", "stabs"))
library(ggplot)
library(ggplot2)
ggplot(Scores, aes(x=condition, y=diffscore, fill=supp)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=diffscore-stderr, ymax=diffscores+stderr),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
ggplot(Scores, aes(x=condition, y=diffscore)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=diffscore-stderr, ymax=diffscores+stderr),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
with(Scores, tapply(ILikeMannerscore, list(condition), stderr), drop=TRUE)
ggplot(Scores, aes(x=condition, y=diffscore)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=diffscore-.36, ymax=diffscores+.36),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
ggplot(Scores, aes(x=condition, y=diffscore)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=diffscore-.36, ymax=diffscore+.36),
width=.2,                    # Width of the error bars
position=position_dodge(.9))
library(hmisc)
install.packages("Hmisc")
library(Hmisc)
plot(Scores$condition, Scores$diffscore, type="n")
with (
data = Scores
, expr = errbar(condition, diffscore, diffscore+.36, diffscore-.36, add=T, pch=1, cap=.1)
)
with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
t.test(Scores[Scores$condition == "Noun",]$diffscore, Scores[Scores$condition == "Verb",]$diffscore)
library(lsr)
cohensD(Scores[Scores$condition == "Noun",]$diffscore, Scores[Scores$condition == "Verb",]$diffscore)
Scores$ILikeMannerscore = Scores$pathscore - Scores$mannerscore
with(Scores, tapply(ILikeMannerscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
with(Scores, tapply(ILikeMannerscore, list(condition),stderr), drop=TRUE)
levels(df.long$condition)
tapply(df.long$diffscore, df.long$condition, length)
tapply(diffscore, list(condition), mean, na.rm=TRUE)
tapply(df.long$diffscore, list(df.long$condition), mean, na.rm=TRUE)
data.summary <- data.frame(
treatment=levels(df.long$condition),
mean=with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
#n=tapply(df.long$diffscore, df.long$condition, length),
#sd=tapply(data.raw$value, data.raw$treatment, sd)
)
data.summary
Scores
with(Scores, tapply(diffscore, list(condition), length)
)
data.summary.diffscores <- data.frame(
treatment=levels(Scores$condition),
mean=with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE)
n=with(Scores, tapply(diffscore, list(condition), length)),
se=with(Scores, tapply(ILikeMannerscore, list(condition), stderr), drop=TRUE)
)
data.summary.diffscores <- data.frame(
treatment=levels(Scores$condition),
mean=with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE),
n=with(Scores, tapply(diffscore, list(condition), length)),
se=with(Scores, tapply(ILikeMannerscore, list(condition), stderr), drop=TRUE)
)
data.summary.diffscores
data.summary.diffscores$me <- qt(1-0.05/2, df=data.summary.diffscores$n)*data.summary.diffscores$se
data.summary.diffscores
data.summary.diffscores <- data.frame(
condition=levels(Scores$condition),
mean=with(Scores, tapply(diffscore, list(condition), mean, na.rm=TRUE), drop=TRUE),
n=with(Scores, tapply(diffscore, list(condition), length)),
se=with(Scores, tapply(ILikeMannerscore, list(condition), stderr), drop=TRUE)
)
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") ) # plot title
#theme_bw() + # remove grey background (because Tufte said so)
#theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph")
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill=cond) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) #
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill=condition) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean, fill=condition)) +
geom_bar(position = position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="blue") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="green") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="brown") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ggtitle("mygraph") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="brown") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se)) +
ylim(0,6) +
ggtitle("Rating of manner vs. path changes - Abs(Difference Scores)") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="brown") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.25) +
ylim(0,6) +
ggtitle("Rating of manner vs. path changes - Abs(Difference Scores)") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="brown") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.25) +
ylim(0,6) +
ylab("Abs(mean(manner) - mean(path))")+
xlab("")+
ggtitle("Rating of manner vs. path changes") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
#dev.off() # Close PNG
# Use ggplot to draw the bar plot!
png('simpledax-barplot-se.png') # Write to PNG
ggplot(data.summary.diffscores, aes(x = condition, y = mean)) +
geom_bar(position = position_dodge(), stat="identity", fill="brown") +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.25) +
ylim(0,6) +
ylab("Abs(mean(manner) - mean(path))")+
xlab("")+
ggtitle("Rating of manner vs. path changes") + # plot title
theme_bw() + # remove grey background (because Tufte said so)
theme(panel.grid.major = element_blank()) # remove x and y major grid lines (because Tufte said so)
dev.off() # Close PNG
